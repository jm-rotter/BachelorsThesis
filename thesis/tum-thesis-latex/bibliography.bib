@inproceedings{taskparallelism,
  author    = {M. Guevara and C. Gregg and K. Hazelwood and K. Skadron},
  title     = {Enabling task parallelism in the CUDA scheduler},
  booktitle = {Workshop on Programming Models for Emerging Architectures},
  year      = {2009},
  pages     = {69--76}
}


@article{Zheng2022LuisaRender,
    author = {Zheng, Shaokun and Zhou, Zhiqian and Chen, Xin and Yan, Difei and Zhang, Chuyan and Geng, Yuefeng and Gu, Yan and Xu, Kun},
    title = {LuisaRender: A High-Performance Rendering Framework with Layered and Unified Interfaces on Stream Architectures},
    year = {2022},
    issue_date = {December 2022},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {41},
    number = {6},
    issn = {0730-0301},
    url = {https://doi.org/10.1145/3550454.3555463},
    doi = {10.1145/3550454.3555463},
    journal = {ACM Trans. Graph.},
    month = {11},
    articleno = {232},
    numpages = {19},
    keywords = {stream architecture, rendering framework, cross-platform renderer}
}

@ARTICLE{proofCNNused,
  title   = "Optical character recognition for self-service banking",
  author  = "Jackel, L D and Sharman, D and Stenard, C E and Strom, B I and
             Zuckert, D",
  journal = "AT\&T Technical Journal",
  year    =  1995
}

@ARTICLE{self_driving_learning,
  title         = "End to end learning for self-driving cars",
  author        = "Bojarski, Mariusz and Del Testa, Davide and Dworakowski,
                   Daniel and Firner, Bernhard and Flepp, Beat and Goyal,
                   Prasoon and Jackel, Lawrence D and Monfort, Mathew and
                   Muller, Urs and Zhang, Jiakai and Zhang, Xin and Zhao, Jake
                   and Zieba, Karol",
  abstract      = "We trained a convolutional neural network (CNN) to map raw
                   pixels from a single front-facing camera directly to
                   steering commands. This end-to-end approach proved
                   surprisingly powerful. With minimum training data from
                   humans the system learns to drive in traffic on local roads
                   with or without lane markings and on highways. It also
                   operates in areas with unclear visual guidance such as in
                   parking lots and on unpaved roads. The system automatically
                   learns internal representations of the necessary processing
                   steps such as detecting useful road features with only the
                   human steering angle as the training signal. We never
                   explicitly trained it to detect, for example, the outline of
                   roads. Compared to explicit decomposition of the problem,
                   such as lane marking detection, path planning, and control,
                   our end-to-end system optimizes all processing steps
                   simultaneously. We argue that this will eventually lead to
                   better performance and smaller systems. Better performance
                   will result because the internal components self-optimize to
                   maximize overall system performance, instead of optimizing
                   human-selected intermediate criteria, e.g., lane detection.
                   Such criteria understandably are selected for ease of human
                   interpretation which doesn't automatically guarantee maximum
                   system performance. Smaller networks are possible because
                   the system learns to solve the problem with the minimal
                   number of processing steps. We used an NVIDIA DevBox and
                   Torch 7 for training and an NVIDIA DRIVE(TM) PX self-driving
                   car computer also running Torch 7 for determining where to
                   drive. The system operates at 30 frames per second (FPS).",
  month         =  apr,
  year          =  2016,
  copyright     = "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CV",
  eprint        = "1604.07316"
}

@ARTICLE{6809196,
  author={Jo, Kichun and Kim, Junsoo and Kim, Dongchul and Jang, Chulhoon and Sunwoo, Myoungho},
  journal={IEEE Transactions on Industrial Electronics}, 
  title={Development of Autonomous Car—Part I: Distributed System Architecture and Development Process}, 
  year={2014},
  volume={61},
  number={12},
  pages={7131-7140},
  keywords={System analysis and design;Mobile robots;Sensors;Automotive engineering;Intelligent vehicles;Standards;Actuators;Software design;Autonomous car;development process;distributed system;FlexRay;system platform},
  doi={10.1109/TIE.2014.2321342}}

@MISC{Krizhevsky_undated-ao,
  title        = "{ImageNet} classification with deep convolutional neural
                  networks",
  author       = "Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E",
  howpublished = "\url{https://proceedings.neurips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf}",
  note         = "Accessed: 2025-7-17"
}

@article{Owens2007-kp,
  title     = "A survey of general‐purpose computation on graphics hardware",
  author    = "Owens, John D and Luebke, David and Govindaraju, Naga and
               Harris, Mark and Kr{\"u}ger, Jens and Lefohn, Aaron E and
               Purcell, Timothy J",
  abstract  = "AbstractThe rapid increase in the performance of graphics
               hardware, coupled with recent improvements in its
               programmability, have made graphics hardware a compelling
               platform for computationally demanding tasks in a wide variety
               of application domains. In this report, we describe, summarize,
               and analyze the latest research in mapping general‐purpose
               computation to graphics hardware.We begin with the technical
               motivations that underlie general‐purpose computation on
               graphics processors (GPGPU) and describe the hardware and
               software developments that have led to the recent interest in
               this field. We then aim the main body of this report at two
               separate audiences. First, we describe the techniques used in
               mapping general‐purpose computation to graphics hardware. We
               believe these techniques will be generally useful for
               researchers who plan to develop the next generation of GPGPU
               algorithms and techniques. Second, we survey and categorize the
               latest developments in general‐purpose application development
               on graphics hardware.",
  journal   = "Comput. Graph. Forum",
  publisher = "Wiley",
  volume    =  26,
  number    =  1,
  pages     = "80--113",
  month     =  mar,
  year      =  2007,
  copyright = "http://onlinelibrary.wiley.com/termsAndConditions\#vor",
  language  = "en"
}




@incollection{JEON2021167,
title = {Chapter Six - Deep learning with GPUs},
editor = {Shiho Kim and Ganesh Chandra Deka},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {122},
pages = {167-215},
year = {2021},
booktitle = {Hardware Accelerator Systems for Artificial Intelligence and Machine Learning},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2020.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S0065245820300905},
author = {Won Jeon and Gun Ko and Jiwon Lee and Hyunwuk Lee and Dongho Ha and Won Woo Ro},
keywords = {Graphics processing unit, Deep learning, Parallel processing, CUDA, Tensor operation, Data center, Edge computing},
abstract = {Deep learning has been extensively researched in various areas and scales up very fast in the last decade. It has deeply permeated into our daily life, such as image classification, video synthesis, autonomous driving, voice recognition, and personalized recommendation systems. The main challenge for most deep learning models, including convolutional neural networks, recurrent neural networks, and recommendation models, is their large amount of computation. Fortunately, most computations in deep learning applications are parallelizable, therefore they can be effectively handled by throughput processors, such as Graphics Processing Units (GPUs). GPUs support high throughput, parallel processing performance, and high memory bandwidth and becomes the most popularly adopted device for deep learning. As a matter of fact, many deep learning workloads from mobile devices to data centers are performed by GPUs. In particular, modern GPU systems provide specialized hardware modules and software stacks for deep learning workloads. In this chapter, we present detailed analysis on the evolution of GPU architectures and the recent hardware and software supports for more efficient acceleration of deep learning in GPUs. Furthermore, we introduce leading-edge researches, challenges, and opportunities of running deep learning workloads on GPUs.}
}


@INPROCEEDINGS{10155700,
  author={Sun, Jinghao and Duan, Kailu and Li, Xisheng and Guan, Nan and Guo, Zhishan and Deng, Qingxu and Tan, Guozhen},
  booktitle={2023 IEEE 29th Real-Time and Embedded Technology and Applications Symposium (RTAS)}, 
  title={Real-Time Scheduling of Autonomous Driving System with Guaranteed Timing Correctness}, 
  year={2023},
  volume={},
  number={},
  pages={185-197},
  keywords={Design methodology;Integer linear programming;Real-time systems;Timing;Behavioral sciences;Iterative methods;Task analysis},
  doi={10.1109/RTAS58335.2023.00022}}

@inproceedings{elliott2011real,
  title={Real-world constraints of GPUs in real-time systems},
  author={Elliott, Glenn A. and Anderson, James H.},
  booktitle={Proceedings of the 2011 Workshop on Cyber-Physical Systems for the Automotive Industry (CPS-NA)},
  year={2011},
  url={https://www.cs.unc.edu/~anderson/papers/cpsna11.pdf}
}

@MISC{nvidiawhitepaper,
  howpublished = "\url{https://images.nvidia.com/content/volta-architecture/pdf/volta-architecture-whitepaper.pdf}",
  note         = "Accessed: 2025-8-17"
}

@misc{yi2024studyperformanceprogrammingcpu,
      title={A Study of Performance Programming of CPU, GPU accelerated Computers and SIMD Architecture}, 
      author={Xinyao Yi},
      year={2024},
      eprint={2409.10661},
      archivePrefix={arXiv},
      primaryClass={cs.DC},
      url={https://arxiv.org/abs/2409.10661}, 
}

@misc{bojarski2016endendlearningselfdriving,
      title={End to End Learning for Self-Driving Cars}, 
      author={Mariusz Bojarski and Davide Del Testa and Daniel Dworakowski and Bernhard Firner and Beat Flepp and Prasoon Goyal and Lawrence D. Jackel and Mathew Monfort and Urs Muller and Jiakai Zhang and Xin Zhang and Jake Zhao and Karol Zieba},
      year={2016},
      eprint={1604.07316},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1604.07316}, 
}

@MISC{Hoffmann_undated-qi,
  title        = "Autonomous automobile trajectory tracking for off-road
                  driving: Controller design, experimental validation and
                  racing",
  author       = "Hoffmann, Gabriel M and Tomlin, Claire J and Montemerlo,
                  Michael and Thrun, Sebastian",
  howpublished = "\url{https://ai.stanford.edu/~gabeh/papers/hoffmann_stanley_control07.pdf}",
  note         = "Accessed: 2025-8-17"
}

@INPROCEEDINGS{rosgm,
  author={Li, Ruoxiang and Hu, Tao and Jiang, Xu and Li, Laiwen and Xing, Wenxuan and Deng, Qingxu and Guan, Nan},
  booktitle={2023 IEEE 29th Real-Time and Embedded Technology and Applications Symposium (RTAS)}, 
  title={ROSGM: A Real-Time GPU Management Framework with Plug-In Policies for ROS 2}, 
  year={2023},
  volume={},
  number={},
  pages={93-105},
  keywords={Runtime;Robot kinematics;Operating systems;Loading;Graphics processing units;Switches;Real-time systems},
  doi={10.1109/RTAS58335.2023.00015}}

@misc{gheibifetrat2025rtgpurealtimecomputinggraphics,
      title={RTGPU: Real-Time Computing with Graphics Processing Units}, 
      author={Atiyeh Gheibi-Fetrat and Amirsaeed Ahmadi-Tonekaboni and Farzam Koohi-Ronaghi and Pariya Hajipour and Sana Babayan-Vanestan and Fatemeh Fotouhi and Elahe Mortazavian-Farsani and Pouria Khajehpour-Dezfouli and Sepideh Safari and Shaahin Hessabi and Hamid Sarbazi-Azad},
      year={2025},
      eprint={2507.06069},
      archivePrefix={arXiv},
      primaryClass={cs.AR},
      url={https://arxiv.org/abs/2507.06069}, 
}

@MISC{luisacoro,
  title       = "{LuisaCompute-coroutine}: {LuisaCompute} with Coroutine
                 Support (Experimental)",
  abstract    = "LuisaCompute with Coroutine Support (Experimental) -
                 LuisaGroup/LuisaCompute-coroutine",
  institution = "Github",
  language    = "en"
}

@MISC{luisa,
  title       = "{LuisaCompute}: {High-Performance} Rendering Framework on
                 Stream Architectures",
  abstract    = "High-Performance Rendering Framework on Stream Architectures -
                 LuisaGroup/LuisaCompute",
  institution = "Github",
  language    = "en"
}

@MISC{halide,
  title       = "Halide: a language for fast, portable data-parallel
                 computation",
  abstract    = "a language for fast, portable data-parallel computation -
                 halide/Halide",
  institution = "Github",
  language    = "en"
}


@misc{mirage,
      title={Mirage: A Multi-Level Superoptimizer for Tensor Programs}, 
      author={Mengdi Wu and Xinhao Cheng and Shengyu Liu and Chunan Shi and Jianan Ji and Kit Ao and Praveen Velliengiri and Xupeng Miao and Oded Padon and Zhihao Jia},
      year={2025},
      eprint={2405.05751},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.05751}, 
}
@MISC{lightker,
  title       = "{LightKer}",
  abstract    = "Contribute to HiPeRT/LightKer development by creating an
                 account on GitHub.",
  institution = "Github",
  language    = "en"
}

@misc{wang2024unleashingpowerpreemptiveprioritybased,
      title={Unleashing the Power of Preemptive Priority-based Scheduling for Real-Time GPU Tasks}, 
      author={Yidi Wang and Cong Liu and Daniel Wong and Hyoseung Kim},
      year={2024},
      eprint={2401.16529},
      archivePrefix={arXiv},
      primaryClass={cs.DC},
      url={https://arxiv.org/abs/2401.16529}, 
}
@misc{apollo,
  author       = {{Baidu Apollo Team}},
  title        = {Apollo: Open Source Autonomous Driving Platform},
  year         = 2017,
  howpublished = {\url{https://github.com/ApolloAuto/apollo}},
  note         = {Accessed: 2025-04-09}
}
@ARTICLE{Tabani2021-gi,
  title         = "Performance analysis and optimization opportunities for
                   {NVIDIA} automotive {GPUs}",
  author        = "Tabani, Hamid and Mazzocchetti, Fabio and Benedicte, Pedro
                   and Abella, Jaume and Cazorla, Francisco J",
  abstract      = "Advanced Driver Assistance Systems (ADAS) and Autonomous
                   Driving (AD) bring unprecedented performance requirements
                   for automotive systems. Graphic Processing Unit (GPU) based
                   platforms have been deployed with the aim of meeting these
                   requirements, being NVIDIA Jetson TX2 and its
                   high-performance successor, NVIDIA AGX Xavier, relevant
                   representatives. However, to what extent high-performance
                   GPU configurations are appropriate for ADAS and AD workloads
                   remains as an open question. This paper analyzes this
                   concern and provides valuable insights on this question by
                   modeling two recent automotive NVIDIA GPU-based platforms,
                   namely TX2 and AGX Xavier. In particular, our work assesses
                   their microarchitectural parameters against relevant
                   benchmarks, identifying GPU setups delivering increased
                   performance within a similar cost envelope, or decreasing
                   hardware costs while preserving original performance levels.
                   Overall, our analysis identifies opportunities for the
                   optimization of automotive GPUs to further increase system
                   efficiency.",
  month         =  apr,
  year          =  2021,
  copyright     = "http://creativecommons.org/licenses/by-nc-nd/4.0/",
  archivePrefix = "arXiv",
  primaryClass  = "cs.AR",
  eprint        = "2104.07735"
}


@article{Zhu2018BaiduAA,
  title={Baidu Apollo Auto-Calibration System: An Industry-Level Data-Driven and Learning-Based Vehicle Longitude Dynamic Calibrating Algorithm},
  author={Fan Zhu and Lin Ma and Xin Xu and Dingfeng Guo and Xiao Cui and Qi Kong},
  journal={arXiv:1808.10134},
  year={2018},
  url={https://arxiv.org/abs/1808.10134}
}
@MISC{nvidia_auto,
  howpublished = "\url{https://images.nvidia.com/aem-dam/en-zz/Solutions/auto-self-driving-safety-report.pdf}",
  note         = "Accessed: 2025-8-17"
}

@techreport{nvidia2017tesla,
  title        = {NVIDIA Tesla V100 GPU Architecture},
  author       = {NVIDIA Corporation},
  year         = 2017,
  institution  = {NVIDIA Corporation},
  url          = {https://images.nvidia.com/content/volta-architecture/pdf/volta-architecture-whitepaper.pdf},
  note         = {Accessed: 2025-04-09}
}
