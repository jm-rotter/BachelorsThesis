@book{latex,
  title = {LaTeX : A Documentation Preparation System User's Guide and Reference Manual},
  publisher = {Addison-Wesley Professional},
  year = {1994},
  author = {Leslie Lamport}
}


@article{Zheng2022LuisaRender,
    author = {Zheng, Shaokun and Zhou, Zhiqian and Chen, Xin and Yan, Difei and Zhang, Chuyan and Geng, Yuefeng and Gu, Yan and Xu, Kun},
    title = {LuisaRender: A High-Performance Rendering Framework with Layered and Unified Interfaces on Stream Architectures},
    year = {2022},
    issue_date = {December 2022},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {41},
    number = {6},
    issn = {0730-0301},
    url = {https://doi.org/10.1145/3550454.3555463},
    doi = {10.1145/3550454.3555463},
    journal = {ACM Trans. Graph.},
    month = {nov},
    articleno = {232},
    numpages = {19},
    keywords = {stream architecture, rendering framework, cross-platform renderer}
}


@incollection{JEON2021167,
title = {Chapter Six - Deep learning with GPUs},
editor = {Shiho Kim and Ganesh Chandra Deka},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {122},
pages = {167-215},
year = {2021},
booktitle = {Hardware Accelerator Systems for Artificial Intelligence and Machine Learning},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2020.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S0065245820300905},
author = {Won Jeon and Gun Ko and Jiwon Lee and Hyunwuk Lee and Dongho Ha and Won Woo Ro},
keywords = {Graphics processing unit, Deep learning, Parallel processing, CUDA, Tensor operation, Data center, Edge computing},
abstract = {Deep learning has been extensively researched in various areas and scales up very fast in the last decade. It has deeply permeated into our daily life, such as image classification, video synthesis, autonomous driving, voice recognition, and personalized recommendation systems. The main challenge for most deep learning models, including convolutional neural networks, recurrent neural networks, and recommendation models, is their large amount of computation. Fortunately, most computations in deep learning applications are parallelizable, therefore they can be effectively handled by throughput processors, such as Graphics Processing Units (GPUs). GPUs support high throughput, parallel processing performance, and high memory bandwidth and becomes the most popularly adopted device for deep learning. As a matter of fact, many deep learning workloads from mobile devices to data centers are performed by GPUs. In particular, modern GPU systems provide specialized hardware modules and software stacks for deep learning workloads. In this chapter, we present detailed analysis on the evolution of GPU architectures and the recent hardware and software supports for more efficient acceleration of deep learning in GPUs. Furthermore, we introduce leading-edge researches, challenges, and opportunities of running deep learning workloads on GPUs.}
}


@INPROCEEDINGS{10155700,
  author={Sun, Jinghao and Duan, Kailu and Li, Xisheng and Guan, Nan and Guo, Zhishan and Deng, Qingxu and Tan, Guozhen},
  booktitle={2023 IEEE 29th Real-Time and Embedded Technology and Applications Symposium (RTAS)}, 
  title={Real-Time Scheduling of Autonomous Driving System with Guaranteed Timing Correctness}, 
  year={2023},
  volume={},
  number={},
  pages={185-197},
  keywords={Design methodology;Integer linear programming;Real-time systems;Timing;Behavioral sciences;Iterative methods;Task analysis},
  doi={10.1109/RTAS58335.2023.00022}}

@inproceedings{elliott2011real,
  title={Real-world constraints of GPUs in real-time systems},
  author={Elliott, Glenn A. and Anderson, James H.},
  booktitle={Proceedings of the 2011 Workshop on Cyber-Physical Systems for the Automotive Industry (CPS-NA)},
  year={2011},
  url={https://www.cs.unc.edu/~anderson/papers/cpsna11.pdf}
}

@misc{apollo,
  author       = {{Baidu Apollo Team}},
  title        = {Apollo: Open Source Autonomous Driving Platform},
  year         = 2017,
  howpublished = {\url{https://github.com/ApolloAuto/apollo}},
  note         = {Accessed: 2025-04-09}
}

@techreport{nvidia2017tesla,
  title        = {NVIDIA Tesla V100 GPU Architecture},
  author       = {NVIDIA Corporation},
  year         = 2017,
  institution  = {NVIDIA Corporation},
  url          = {https://images.nvidia.com/content/volta-architecture/pdf/volta-architecture-whitepaper.pdf},
  note         = {Accessed: 2025-04-09}
}
