% !TeX root = ../main.tex

\chapter{Related Work}\label{chapter:Related Work}


The increasing use of GPUs in real time systems has led to the development of custom programming models designed to reduce kernel launch overhead and improve predictable GPU scheduling.
Such models are particularly useful in systems where minimizing execution latency, improving resource utilization, and mainting timing determinism is important.
These approaches can be broadly categorized into compiler driven frameworks, runtime scheduling frameworks, and manual implementations, the latter of which is the focus of this work.


\section{Compiler Driven Frameworks}

Compiler driven frameworks optimize GPU workloads through automated code generation. 
The user writes codes in a high level \acs{DSL} that abstracts low level device details.
At runtime, the framework parses the \acs{DSL} into an \acs{AST}, which is then converted into an \acs{IR}. 
From this intermediate representation, the compiler applies transformations and optimizations before compiling the code \acs{JIT} into GPU executable device code.

Several projects demonstrate how these frameworks are applied in practice. 
\textit{Mirage}, for example, improves large language inference by fusing kernels into a single megakernel \cite{mirage}.
This achieves the same effect as persistent threads in removing extra kernel task scheduling overhead.
Similarily, \textit{Halide} seperates algorithm specification from execution schedule, allowing compiler autoschedulers to optimize performance with minimal manual tuning \cite{halide}.
Finally, \textit{Luisa} targets graphics and simulation workloads, offering acceleration structures, ray traversal APIs and shader abstraction to provide high level rendering code while retaining low level performance \cite{luisa}. 

Luisa, in particular, offers a model that can be adapted for real time applications. 
Built on top of Luisa's execution model, \textit{LuisaCompute-Coroutines} extends the framework to support coroutines running on persistent threads \cite{luisacoro}. 
Coroutines are expressed simply within the \acs{DSL} as explicit suspension points, which allow the device to preserve context and yield, enabling fine grained scheduling. 
This approach is especially efficient and well suited for real time systesms, as it leverages asynchronous coroutine execution to improve responsiveness and resource utilization. 


\section{Runtime Scheduling Frameworks}

Beyond compiler based transformation and code generation, runtime based frameworks offer an alternative approach by enabling real time GPU scheduling.
For example, \textit{RT-GPU}, a runtime system, provides deadline aware scheduling of GPU workloads by partitioning GPU resources \cite{gheibifetrat2025rtgpurealtimecomputinggraphics}. 
Using a reservation based model, RT-GPU enables fine grained control over scheduling to ensure the task deadlines are met. 
Additionally, \textit{ROSGM} is a GPU management framework designed specificially for ROS 2 robotics systems \cite{rosgm}.  
ROSGM interposes a layer to intercept the CUDA API calls and attach metadata to each GPU task, allowing custom deadlines and priorities to manage how GPU tasks are queued and issued to the device. 

\vspace{\baselineskip}

Overall, these frameworks demonstrate different approaches to achieving predictable GPU execution.
Each of these frameworks relies on a form of high level user abstraction to manage scheduling and low level execution.
While compiler and runtime systems simplify development through abstraction and automation, they do not allow for highly application specific fine tuning.
Manual implementations, in contrast, enable this level of control and form the basis for the fine grained GPU scheduling explored in this thesis.
