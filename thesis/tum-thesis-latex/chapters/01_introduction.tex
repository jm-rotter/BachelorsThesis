% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Introduction}\label{chapter:introduction}

\section{Motivation}
Autonomous driving systems place stringent demands on computational performance, predictability and safety \cite{nvidia_auto}.
These demands arise from the need to process vast amounts of sensor data and run complex perception and decision making algorithms in real time, while ensuring timely and deterministic responses to a dynamic environment.
To meet the computational requirements of such systems, \acsp{GPU} have become essential due to their performance on machine learning workloads. 
However, the current GPU programming and execution model is poorly suited to real time constraints \cite{elliott2011real}. 
The autnomous driving platform, Apollo, which serves as the primary motivation for this thesis, illustrates this challenge \cite{Zhu2018BaiduAA} \cite{apollo}.
While Apollo integrates GPU accelerated workloads, it does not natively provide real time GPU support.
Although this thesis does not implement the proposed approach directly within Apollo, the challenges of meeting real time requirements in autonomous systems, particularly in GPU workloads, serve as the central motivation for this research.


\subsection{Evolution of Autonomous Driving Architectures}
Historically, early autonomous driving systems addressed the real time requirements using a distributed architecture.
In this approach, major functional modules, such as perception, localization, planning, and control, were mapped to seperate compute units, which together formed a processing pipeline \cite{6809196}. 
Each module could thus operate with predictable timing characteristics, avoiding contention with other modules. 
In this manner, the distributed architecture allowed for fine tuning the timing between modules to achieve low latency responses from the hardware. 
This modular architecture ensured responsiveness and real time guarantees at the expense of high hardware cost and increased system complexity.


The rise of increasingly powerful GPUs has enabled a shift toward centralized computing in order to simplify the hardware and complexity while reducing costs \cite{Tabani2021-gi}. 
In this centralized architecture, all core driving modules share a common compute node consisting of a heterogeneous CPU-GPU system. 
The compute node integrates a CPU for task scheduling and system control, which assigns compute heavy workloads to the GPU.
Moving to a singular compute node allows savings in cost, design, and intermodule latency.

\subsection{Limitations of Current GPU Execution Models}

Despite the benefits afforded by a centralized architecture and the advances in hardware, the system risks GPU oversubscription.
As the GPU is responsible for all processing tasks, too many simultaneously scheduled tasks can lead to delays in execution time. 
Typical real time solutions based on a \acs{CPU} architecture, ensure system safety under contention by preempting non critical tasks. 
Tasks requiring high responsiveness can then be directly executed after preemption of the resident processes.
Although there already exists native support for this preemption on \acsp{CPU} within both the kernel and user space, \acsp{GPU} currently lack such capabilities. 

Modern GPUs do not natively support real time programming models in the same way CPUs do \cite{wang2024unleashingpowerpreemptiveprioritybased}.
GPU execution is managed by a hardware scheduler that handles thread blocks, warps and memory accesses according to fixed, internal policies. 
This internal GPU hardware scheduler is optimized for throughput rather than deterministic execution, required by real time systems. 
In effect, programmers have limited control over the exact scheduling of threads or tasks, when using standard scheduling techniques. 
Critically, tasks with strict timing requirements may suffer delays if long running, lower priority kernels are already resident on the device. 
The inability to natively preempt GPU kernels or to enforce strict task priorities makes using standard GPU kernel scheduling methods unsuitable for safety critical, real time workloads.  
Particularily in the context of autonomous driving, the repercussions of latencies pose a safety hazard. 


\section{Problem Statement}

Rather than relying on native kernel launches, this thesis investigates the use of persistent threads to enable low latency execution and develops the foundational framework needed to integrate coroutines into the system for further real time determinism.
Persistent threads are specialized kernels that are launched at the start of the application and remain active throughout the lifetime of the system. 
They function as a user level scheduler, continuously polling for work, executing tasks, and executing scheduling decisions. 

Building on this framework, the central research question addressed in this thesis is:

\vspace{\baselineskip}

\textbf{How can a persistent GPU thread model be designed to enable the implementation of GPU coroutines for predictable, low latency scheduling on real time systems?}

\vspace{\baselineskip}

As part of this research, the following aspects of the persistent threaded implementation will be considered and evaluated:

\begin{itemize}

    \item \textbf{GPU Task Management:} Mechanism for submitting tasks to the GPU and retrieving results asynchronously.
    
	\item \textbf{GPU Device Memory Management:} Efficient allocation, deallocation, and usage of GPU memory to ensure low latency access and avoid contention between tasks.

    \item \textbf{GPU Stream Management:} Organizing and scheduling multiple GPU streams to enable concurrent task execution with memory transfers, while maintaining predictable execution orders.
    
    \item \textbf{Framework for Coroutines:} Designing a foundation for GPU coroutines that allows cooperative multitasking and the implementation of custom scheduling strategies on top of persistent threads.

\end{itemize}





